---
title: "Angel_pstat126_Project_week2"
author: "Angel Abdulnour, Andrew Hansen, Sammy Suliman"
date: "2023-04-29"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(skimr)
library(dplyr)
library(caret)
#install.packages("olsrr")
#install.packages("lmtest")
library("lmtest")
library("olsrr")
```


```{r, results='hide'}
# Used to load data set. In read.csv paste personalized file path
performance <- read.csv("C:/Users/Angel/OneDrive/Desktop/schoolwork/1. Pstat 126/pstat-126/student/student-por.csv", header=TRUE, stringsAsFactors=FALSE, sep=';')
performance
```



Review: The UCI student performance dataset has 16 numeric variables. Of those we have the three response variables, G1, G2, and G3, which represent the student's grades in each quarter respectively (for the sake of our project we wil be using G3). There are 13 numeric predictor variables and we will be using Studytime as the main predictor variable in our simple linear regression model. studytime is the hours of studying they have done per week where 1 = less than 2 hours, 2 = 2-5 hours, 3 = 5-10 hours, and 4 = greater than 10 hours.

Our null hypothesis for this test going forward will be that studytime does not hold any significance in determining the response variable. 
our alternative hypothesis being that studytime is significant enough to actually affect the response variable



Our first step is to see if we fall under the assumptions for linear regression. We create the numeric data set and pick out just the studytime and G3 variables.

```{r}
numeric_performance <- performance %>% select_if(is.numeric)
fit  <- lm(G3 ~ studytime, data = numeric_performance)
summary(fit)
```
Here we use a scatter plot and QQ polt and can see that neither linearity nor normality is proven since the red line is not on 0 and the qq plot is very step shaped.
```{r}
plot(fit)

```

since the p-value s higher than 0.05 the BP test proves that it is does not have heteroskedasticity and has homoskedasticity
```{r}
bptest(fit)
```

Since the previous data was not linear nor normal we will try to fix it by taking the log of the predictor variable and plotting that
```{r}
numeric_performance <- performance %>% select_if(is.numeric)
logfit  <- lm(G3 ~ log(studytime), data = numeric_performance)
summary(fit)
```
next we check the normality of the residuals by checking the qq plot. since it seems like many of the points fall ont he line it is safe to consider it normal. Furthermore, by the red trend line on the scatter plot, we can see that the mean is 0 which proves linearity.
```{r}
plot(logfit)

```

since the p-value s higher than 0.05 the BP test proves that it is does not have heteroskedasticity and has homoskedasticity
```{r}
bptest(logfit)
```
We have proven linearity, normality, and homoskedasticity which makes this data safe to be used for a linear regression model.


The next step to be completed is test of B1 or finding a confidence interval for B1. To do this we are using the confidence interval
```{r}
confint(logfit, "log(studytime)", level = 0.95)
```
first thing we need to do since we took the log of the variable is now put the endpoints of the confidence interval as a power of e. $\exp{1.352548} = 3.867266783$ and $\exp{2.454701} = 11.64295179$.
What this means is that each time a student's amount of study hours goes up a bracket in the studytime variable (from 1 to 2 means <2hrs of study to 2-5 hrs of studying respecctively) then their G3 grade will go up by anywhere between 3.867266783 to 11.64295179. This does not tell us too much information becasue going from bracket 2 to 3 could mean going from 5 to 6 hours of studying or 2 to 10 hours of studying per week, and similar reasoning could be used between the other brackets.


here is the confidence interval that we take about the mean. first we find the mean of G3, then the standard deviation. then we find the distance from the mean that we are allowed to be away from while still creating an interval that will contain the mean with a 95% confidence rate
```{r}
n <- dim(numeric_performance)[1]
ybar <- mean(numeric_performance$G3)
s <- sd((numeric_performance$G3))
margin <- qt(0.975, df = n-1)*s/sqrt(n)
low <- ybar - margin
high <- ybar + margin
low
high
```
this is the mean value of G3 of all the students that have studied a bracket of 2. G3 is the 16th variable  we then construct an interval that will contain G3 95% of the time
```{r}
y2bar <- mean(numeric_performance[(numeric_performance$studytime) == '2', ][,16])
y2bar
s2 <- sd((numeric_performance$G3))
margin2 <- qt(0.975, df = n-1)*s/sqrt(n)
low2 <- y2bar - margin2
high2 <- y2bar + margin2
low2
high2
```

```{r}
summary(logfit)$r.squared
```
Our r-squared value, 0.06639289, is very low. This means our model explains a low percentage of the variance.Furthermore, our residual plots did not demonstrate linearity and normality as much as we would have liked. We had to take logs of the variable and even then, they were not the best. The mean, shown in the scatter plot, was a little off and the QQ plot still had a little bit of a stairway pattern and was not a line. This means that a linear model is not the most appropriate for our data.


I think it was interesting to see how the average studying done by the students landed in the 2 bracket (about 1.93) which is near the middle of the 4 brackets, and the average grade was around 11 which is also half of the maximum grade they could receive. We hypothesized the data to follow a roughly normal distribution, however, even taking the log did not produce a normal distribution. This means that even a data set with 649 samples might not be normal. One thing that I would like to ask about the data is where these students were selected.